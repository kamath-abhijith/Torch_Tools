{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b805db8",
   "metadata": {},
   "source": [
    "# OOP Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032480c",
   "metadata": {},
   "source": [
    "Let's create deep networks using ```nn.Module``` from torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa7c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e92522",
   "metadata": {},
   "source": [
    "Let's first make a network prototype. The class must initialise the network and have a module that executes a forward pass. We will rely on ```nn.Module``` to perform backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypeNetwork:\n",
    "    def __init__(self):\n",
    "        self.layer = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1904de0",
   "metadata": {},
   "source": [
    "Let's use the ```nn.Module``` class and initialise the parent class using the ```super()``` constructor. We will define a convolutional network with:\n",
    "- Convolutional layer with 6 output channels\n",
    "- Convolutional layer with 12 output channels\n",
    "- Dense layer with 120 output nodes\n",
    "- Dense layer with 60 output nodes\n",
    "- Dense layer with 10 output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9708a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.dense2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Revisit later\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5d269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dense1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (dense2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = ConvNetwork()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac6df8",
   "metadata": {},
   "source": [
    "We can see the weights in the layers that are randomly initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa430f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1889, -0.1850, -0.0487, -0.0466,  0.1180],\n",
      "          [-0.1314, -0.1771,  0.0952,  0.0582,  0.0288],\n",
      "          [ 0.0774,  0.0185, -0.1531,  0.0924,  0.0270],\n",
      "          [ 0.1145, -0.0294, -0.1455,  0.0755, -0.1431],\n",
      "          [-0.0671,  0.0907,  0.0849, -0.0041,  0.1573]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1938, -0.0258, -0.0250, -0.1817,  0.0395],\n",
      "          [-0.0681, -0.0891,  0.1766,  0.0535, -0.1912],\n",
      "          [-0.0355, -0.0394, -0.1643, -0.1877, -0.0632],\n",
      "          [ 0.1463,  0.1823,  0.0186,  0.1890,  0.0853],\n",
      "          [-0.1790, -0.0165,  0.1380,  0.1172, -0.1004]]],\n",
      "\n",
      "\n",
      "        [[[-0.1974, -0.0381, -0.1312, -0.1662, -0.1308],\n",
      "          [-0.0140,  0.0047,  0.0836,  0.0262, -0.0043],\n",
      "          [ 0.0654, -0.1568, -0.1692, -0.1703,  0.1845],\n",
      "          [ 0.0156, -0.0285,  0.1867, -0.1354, -0.0268],\n",
      "          [ 0.1510, -0.0729,  0.1017, -0.0110,  0.0435]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1860, -0.0351,  0.1267,  0.0503,  0.0356],\n",
      "          [-0.1416, -0.0794,  0.0410, -0.1613,  0.1879],\n",
      "          [-0.0518,  0.1747, -0.1190,  0.0687, -0.0214],\n",
      "          [ 0.1275,  0.0536, -0.0735,  0.1002,  0.1625],\n",
      "          [-0.1314, -0.1454,  0.0991, -0.1668, -0.1300]]],\n",
      "\n",
      "\n",
      "        [[[-0.1764, -0.1646,  0.0625,  0.0069,  0.1438],\n",
      "          [ 0.1002, -0.1231, -0.1433, -0.0275, -0.1617],\n",
      "          [-0.1303,  0.0832, -0.0341, -0.1845, -0.0342],\n",
      "          [ 0.1113,  0.1796, -0.1724, -0.0303, -0.1131],\n",
      "          [-0.0150, -0.0621, -0.0765,  0.1736,  0.0361]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1460,  0.1643, -0.1935, -0.0026, -0.1646],\n",
      "          [-0.1501, -0.1394, -0.1344,  0.0130, -0.1412],\n",
      "          [-0.1313, -0.0048,  0.0020, -0.0197,  0.1463],\n",
      "          [ 0.0039,  0.0647,  0.1094, -0.1275, -0.1356],\n",
      "          [ 0.1098, -0.0208, -0.1384,  0.1378,  0.0410]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.shape)\n",
    "print(network.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9d5fd",
   "metadata": {},
   "source": [
    "Notice that the size of the weights matches the specifications. Also, the weight tensor has an attribute ```requires_grad``` that flags the weight variable to be included in that computational graph that computes the derivatives during backpropagation. This weight is called a **learnable parameter**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b29d4c",
   "metadata": {},
   "source": [
    "We can check all the learnable parameters and their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e575f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "dense1.weight \t\t torch.Size([120, 192])\n",
      "dense1.bias \t\t torch.Size([120])\n",
      "dense2.weight \t\t torch.Size([60, 120])\n",
      "dense2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
