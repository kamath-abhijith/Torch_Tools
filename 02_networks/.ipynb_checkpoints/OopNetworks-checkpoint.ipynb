{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b805db8",
   "metadata": {},
   "source": [
    "# OOP Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032480c",
   "metadata": {},
   "source": [
    "Let's create deep networks using ```nn.Module``` from torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaa7c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e92522",
   "metadata": {},
   "source": [
    "Let's first make a network prototype. The class must initialise the network and have a module that executes a forward pass. We will rely on ```nn.Module``` to perform backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "080cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypeNetwork:\n",
    "    def __init__(self):\n",
    "        self.layer = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1904de0",
   "metadata": {},
   "source": [
    "Let's use the ```nn.Module``` class and initialise the parent class using the ```super()``` constructor. We will define a convolutional network with:\n",
    "- Convolutional layer with 6 output channels\n",
    "- Convolutional layer with 12 output channels\n",
    "- Dense layer with 120 output nodes\n",
    "- Dense layer with 60 output nodes\n",
    "- Dense layer with 10 output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9708a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.dense2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e5d269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dense1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (dense2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = ConvNetwork()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac6df8",
   "metadata": {},
   "source": [
    "We can see the weights in the layers that are randomly initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa430f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0233, -0.1135,  0.1830, -0.0416,  0.0017],\n",
      "          [ 0.1942, -0.0306, -0.0012, -0.0623,  0.0258],\n",
      "          [ 0.1327, -0.1535, -0.1877,  0.0392, -0.0210],\n",
      "          [ 0.1843, -0.1174, -0.0224, -0.1377, -0.1517],\n",
      "          [ 0.0851,  0.1210, -0.0700,  0.0906, -0.1735]]],\n",
      "\n",
      "\n",
      "        [[[-0.1625,  0.0780,  0.0615,  0.1024, -0.0930],\n",
      "          [-0.0529, -0.1667,  0.1398,  0.1927,  0.0025],\n",
      "          [-0.0511,  0.0116,  0.0833, -0.0305, -0.0467],\n",
      "          [ 0.0378,  0.1026, -0.0568,  0.1405,  0.1570],\n",
      "          [-0.0653, -0.0638, -0.0920, -0.1901, -0.0884]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0537, -0.0646,  0.1846,  0.1493, -0.1202],\n",
      "          [-0.1225,  0.1394,  0.0595,  0.1275, -0.0689],\n",
      "          [-0.0991,  0.0358, -0.0381,  0.0840,  0.1535],\n",
      "          [ 0.1819,  0.0755, -0.1705, -0.1102, -0.1975],\n",
      "          [ 0.1596,  0.0376,  0.0377,  0.0608, -0.1556]]],\n",
      "\n",
      "\n",
      "        [[[-0.1435,  0.1322, -0.0235, -0.0969,  0.1806],\n",
      "          [-0.0618, -0.1401, -0.0284,  0.0221, -0.1229],\n",
      "          [-0.1023, -0.1134, -0.0872, -0.1371, -0.1495],\n",
      "          [ 0.1165, -0.1692,  0.0323, -0.1263,  0.0857],\n",
      "          [-0.1742,  0.1871,  0.0580, -0.1279,  0.1175]]],\n",
      "\n",
      "\n",
      "        [[[-0.1199,  0.0732, -0.0074, -0.0613, -0.1719],\n",
      "          [ 0.1100,  0.0148,  0.1692, -0.1182,  0.1401],\n",
      "          [-0.1267,  0.1965, -0.1899, -0.0857,  0.0950],\n",
      "          [ 0.0728, -0.1344, -0.1213,  0.0374, -0.0991],\n",
      "          [ 0.1679,  0.0173,  0.0374,  0.0376,  0.1302]]],\n",
      "\n",
      "\n",
      "        [[[-0.0784,  0.1102, -0.0165,  0.0743, -0.0467],\n",
      "          [-0.1254, -0.0641, -0.1383, -0.1553,  0.1191],\n",
      "          [-0.1288, -0.0655, -0.0940, -0.0466, -0.0825],\n",
      "          [ 0.1086,  0.1534,  0.1001, -0.1528,  0.0907],\n",
      "          [-0.0773, -0.0339,  0.1999,  0.0290,  0.1584]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.shape)\n",
    "print(network.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9d5fd",
   "metadata": {},
   "source": [
    "Notice that the size of the weights matches the specifications. Also, the weight tensor has an attribute ```requires_grad``` that flags the weight variable to be included in that computational graph that computes the derivatives during backpropagation. This weight is called a **learnable parameter**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b29d4c",
   "metadata": {},
   "source": [
    "We can check all the learnable parameters and their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e575f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "dense1.weight \t\t torch.Size([120, 192])\n",
      "dense1.bias \t\t torch.Size([120])\n",
      "dense2.weight \t\t torch.Size([60, 120])\n",
      "dense2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
