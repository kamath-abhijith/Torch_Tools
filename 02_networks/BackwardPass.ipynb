{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062df5ac",
   "metadata": {},
   "source": [
    "# Training using Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe63b5",
   "metadata": {},
   "source": [
    "Let's use the ```autograd``` feature to enable training using backpropagation. A general flow of training follows:\n",
    "- Repeat for as many epochs:\n",
    "    - Repeat until one epoch:\n",
    "        - Extract a batch from the training set,\n",
    "        - Execute a **forward pass** to obtain predictions on the batch,\n",
    "        - Compute the **loss**,\n",
    "        - Compute the **gradient** of the loss function w.r.t the weights using ```autograd```,\n",
    "        - **Update the weights** using the gradients propagated using backpropagation,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1e29620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from scipy import io\n",
    "from torch import nn\n",
    "from torch import optim \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abcd11",
   "metadata": {},
   "source": [
    "Let's set the following:\n",
    "- Training dataset - MNIST with batch size $100$\n",
    "- Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cbfc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        data = io.loadmat('./../datasets/MNIST/mnist_training_data.mat')\n",
    "        labels = io.loadmat('./../datasets/MNIST/mnist_training_label.mat')\n",
    "        \n",
    "        self.num_samples = len(data['training_data'])\n",
    "        self.samples = data['training_data'].reshape(self.num_samples, 28, 28)[:,None].astype(np.float32)\n",
    "        self.targets = labels['training_label'][:,0].astype(np.int64)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            return self.transform(self.samples[index]), self.targets[index]\n",
    "        else:\n",
    "            return self.samples[index], self.targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c16ee7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[0 0 0 ... 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "train_set = MNIST()\n",
    "print(len(train_set))\n",
    "print(train_set.targets)\n",
    "# print(train_data.targets.bincount())\n",
    "# Make bincount feature, comment on the balance of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32579ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc1e80",
   "metadata": {},
   "source": [
    "Let's use the convolutional neural network and instantiate an object network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "910aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.dense2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (1) hidden conv layer\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden linear layer\n",
    "        x = x.reshape(-1, 12*4*4)\n",
    "        x = self.dense1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        x = self.dense2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # (5) output layer\n",
    "        x = self.out(x)\n",
    "        # x = F.softmax(x, dim=1) # This will be implemented within the loss function\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "976e34df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dense1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (dense2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = ConvNetwork()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4abc5",
   "metadata": {},
   "source": [
    "Let's compute the cross-entropy loss on one batch, and also, see how many predictions it gets right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6e30b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(predictions, labels):\n",
    "    return F.softmax(predictions, dim=1).argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aba423ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3baac5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3098042011260986"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = network(images)\n",
    "loss = F.cross_entropy(predictions, labels)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d253b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaef297",
   "metadata": {},
   "source": [
    "Let's use the ```backward()``` module attached to the loss function to compute the gradients using backpropagation. The gradients can be computed using the computational graph that is carried over to the loss function by the ```predictions``` tensor computed during the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc4948d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1182cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3ad84e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.0024e-04,  6.7776e-04,  6.6709e-04,  8.9709e-04,  1.0035e-03],\n",
      "          [ 1.3444e-03,  1.1197e-03,  6.9950e-04,  3.4294e-04,  8.9420e-04],\n",
      "          [ 1.0179e-03,  1.9818e-04,  2.7285e-04,  8.6131e-04,  1.9530e-03],\n",
      "          [ 8.2348e-04,  2.1270e-04,  4.4001e-04,  1.5023e-03,  2.4396e-03],\n",
      "          [ 5.9178e-04,  2.3150e-04,  1.0605e-03,  1.8462e-03,  2.3944e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.1652e-04, -1.4356e-04, -3.0494e-04, -7.2880e-04, -1.3777e-03],\n",
      "          [ 1.3309e-04,  5.5074e-04,  1.5907e-04,  2.3878e-04, -1.3154e-03],\n",
      "          [ 1.2052e-03,  1.1874e-03,  6.3362e-04,  6.8915e-04, -1.2664e-03],\n",
      "          [ 1.4353e-03,  1.2919e-03,  4.9581e-04,  1.1869e-04, -1.9263e-03],\n",
      "          [ 1.2097e-03,  1.0014e-03,  5.0995e-04, -3.8542e-04, -1.8888e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0951e-03,  9.5744e-04,  3.5992e-04, -2.0244e-05, -3.6566e-05],\n",
      "          [ 5.6199e-04,  7.0101e-04,  6.5007e-04,  2.5849e-04,  3.0237e-05],\n",
      "          [ 7.0865e-04,  9.5106e-04,  7.1071e-04,  1.1685e-04, -4.9036e-07],\n",
      "          [ 8.8529e-04,  7.7504e-04,  1.3827e-04, -1.2680e-06, -1.4072e-05],\n",
      "          [ 8.7513e-04,  5.2397e-04, -2.3282e-06,  5.4896e-05, -2.4649e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.2854e-03, -8.9908e-04, -1.2078e-04,  4.0481e-04,  1.1835e-03],\n",
      "          [-7.7133e-04, -4.4193e-04, -3.1839e-04,  3.2827e-05,  9.8599e-04],\n",
      "          [ 1.7617e-05, -8.5301e-05, -5.0330e-04, -4.0493e-04,  6.7384e-04],\n",
      "          [ 3.7775e-04,  1.8013e-04, -1.7024e-05,  2.7109e-04,  1.4392e-03],\n",
      "          [ 6.3521e-04,  3.0288e-04,  3.0590e-04,  5.8833e-04,  1.2515e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.8587e-04, -3.3327e-04, -6.1456e-05, -1.6289e-04, -3.6234e-04],\n",
      "          [-1.1173e-03, -4.4167e-04, -1.2280e-04, -4.9183e-05, -5.7782e-05],\n",
      "          [-9.8087e-04, -1.9501e-04,  5.4256e-04,  1.0850e-03,  9.5706e-04],\n",
      "          [-9.7047e-04,  4.8380e-04,  1.2959e-03,  1.5979e-03,  1.0268e-03],\n",
      "          [-1.1775e-03,  9.6429e-05,  1.1803e-03,  9.2503e-04,  7.9796e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5537e-03, -2.1863e-03, -1.7594e-03, -1.1840e-04,  4.9833e-04],\n",
      "          [-1.0948e-03, -2.4065e-03, -2.1416e-03, -1.0936e-03, -8.8445e-05],\n",
      "          [-1.4164e-03, -2.0906e-03, -1.9235e-03, -8.6301e-04,  3.8797e-05],\n",
      "          [-1.1313e-03, -1.7726e-03, -1.4352e-03,  8.1334e-05,  1.4240e-03],\n",
      "          [-1.3074e-03, -1.5534e-03, -7.1852e-04,  1.1296e-03,  1.9016e-03]]]])\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.grad)\n",
    "print(network.conv1.weight.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c9400",
   "metadata": {},
   "source": [
    "Notice that the gradient of the loss w.r.t the weights of ```conv1``` have the same shape as the weights of the layer. Using these gradients, we use an optimiser to update all parameters of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20160539",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(network.parameters(), lr=0.01)\n",
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e96b2699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2640018463134766"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = network(images)\n",
    "loss = F.cross_entropy(predictions, labels)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c001add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091558c",
   "metadata": {},
   "source": [
    "We expect the loss on the same batch to decrese and the number of correct predictions to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad096ea",
   "metadata": {},
   "source": [
    "We can now put all this together to train with all the images to make an epoch, and then to run multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cc1a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 accuracy:  0.9321600000000004 loss:  106.51637787092477\n",
      "epoch:  1 accuracy:  0.9765 loss:  39.997753218747675\n",
      "epoch:  2 accuracy:  0.9806399999999998 loss:  33.283312194165774\n",
      "epoch:  3 accuracy:  0.9811799999999992 loss:  31.91149481764296\n",
      "epoch:  4 accuracy:  0.9820799999999991 loss:  32.08094493061071\n",
      "epoch:  5 accuracy:  0.9832399999999979 loss:  29.699549744153046\n",
      "epoch:  6 accuracy:  0.9842999999999988 loss:  28.690777756128227\n",
      "epoch:  7 accuracy:  0.9860999999999983 loss:  25.455984299827833\n",
      "epoch:  8 accuracy:  0.9841999999999984 loss:  29.483688041975256\n",
      "epoch:  9 accuracy:  0.9858999999999979 loss:  27.84778618204291\n"
     ]
    }
   ],
   "source": [
    "model = ConvNetwork()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    for batch in train_loader:\n",
    "        # Load a batch\n",
    "        images, labels = batch\n",
    "        \n",
    "        # Execute a forward pass\n",
    "        predictions = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = F.cross_entropy(predictions, labels)\n",
    "        \n",
    "        # Compute gradients\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimiser.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        accuracy += get_num_correct(predictions, labels) / len(train_set)\n",
    "        \n",
    "    print(\"epoch: \", epoch, \"accuracy: \", accuracy, \"loss: \", total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
